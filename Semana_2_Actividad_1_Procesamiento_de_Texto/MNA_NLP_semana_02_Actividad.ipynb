{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "70StdqAZa9E9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jogabenn/Actividades-Estrategia-de-Implementacion-de-Servicios-Tecnologicos/blob/main/Semana_2_Actividad_1_Procesamiento_de_Texto/MNA_NLP_semana_02_Actividad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Procesamiento de Lenguaje Natural (NLP)**\n",
        "###Tecnológico de Monterrey\n",
        "###Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Adtividad de la Semana 02**\n",
        "###**Introducción al procesamiento de texto.**\n",
        "\n",
        "###**Alumno: Jonathan Garza Bennet - A01793038**"
      ],
      "metadata": {
        "id": "759SG4TyfbUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta actividad deberás utilizar los datos del siguiente archivo que se encuentra en Canvas:\n",
        "\n",
        "MNA_NLP_semana_02_Actividad_datos.txt\n",
        "\n",
        "El archivo contiene comentarios en inglés sobre servicios de comida de la página de Yelp: https://www.yelp.com/ . \n",
        "\n",
        "Son mil comentarios y forman parte del conjunto de datos que se encuentra en el Machine Learning Repository de la UCI, llamado \"Sentiment Labelled Sentences\": https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#\n"
      ],
      "metadata": {
        "id": "6ue1YAKx3XDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 1. Cargamos los datos.**   "
      ],
      "metadata": {
        "id": "Zj-h4drXD-X9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar los datos del archivo indicado y obtener una lista de longitud de 1000 strings/comentarios. \n",
        "\n",
        "Por el momento solamente requerimos las bibliotecas de Numpy y re, para el manejo de los arreglos y de las expresiones regulares en Python.\n",
        "\n",
        "En particular, no necesitarás en esta actividad la biblioteca de Pandas.\n",
        "\n",
        "###**NOTA: En esta actividad no debes importar nada más, con estas dos bibliotecas será *suficiente*.**"
      ],
      "metadata": {
        "id": "BY6yifxscfrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np    # importamos Numpy para el manejo de los arreglos.\n",
        "import re             # importamos re para el manejo de las expresiones regulares."
      ],
      "metadata": {
        "id": "OJ26dAfhdFnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecuta las siguientes instrucciones para cargar la información del achivo dado:\n",
        "\n",
        "#Se carga el archivo en el entorno temporal de ejecución en la siguiente ruta. Para cargar los archivos desde una URL se requiere importar módulos adicionales.\n",
        "with open('/content/sample_data/MNA_NLP_semana_02_Actividad_datos.txt',        # puedes actualizar la ruta a tu archivo, en dado caso.\n",
        "          mode='r',     # abrimos el archivo en modo lectura.\n",
        "          ) as f:\n",
        "    docs = f.readlines()    # separamos cada comentario por líneas\n",
        "\n",
        "f.close()  # ya que tenemos la información en la variable docs, cerramos el archivo"
      ],
      "metadata": {
        "id": "QHUmJyjDdGNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(docs) == list   # Verifica que tu variable \"docs\" es una lista"
      ],
      "metadata": {
        "id": "L6WzrSrodG-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7407047-c990-4a41-9081-d1f618e72781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)==1000  # verifica que la longitud de \"docs\" es de mil comentarios."
      ],
      "metadata": {
        "id": "QIK1u9WS2FtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3de8adf-911d-4ef9-cf40-bf56df995872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0:10]     # observa algunos de los primeros comentarios"
      ],
      "metadata": {
        "id": "9AMLIfQvJqNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48e156c-c34b-4fca-f1aa-396b4feaaff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.\\n',\n",
              " 'Crust is not good.\\n',\n",
              " 'Not tasty and the texture was just nasty.\\n',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\\n',\n",
              " 'The selection on the menu was great and so were the prices.\\n',\n",
              " 'Now I am getting angry and I want my damn pho.\\n',\n",
              " \"Honeslty it didn't taste THAT fresh.)\\n\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\\n',\n",
              " 'The fries were great too.\\n',\n",
              " 'A great touch.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 2: sección de preguntas (regex).**   \n"
      ],
      "metadata": {
        "id": "k_ewoagic5jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Instrucciones:**\n",
        "\n",
        "###**A continuación deberás contestar cada una de las preguntas que te piden usando expresiones regulares (regex).**\n",
        "\n",
        "###**Por el momento no hay restricción en cuanto al número de líneas de código que agregues, pero trata de incluir las mínimas posibles.**"
      ],
      "metadata": {
        "id": "X-eMJa3DFCIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 1.** \n",
        "\n",
        "Busca y elimina todos los saltos de línea '\\n' que se encuentran al final de cada comentario. \n",
        "\n",
        "Una vez finalizado, imprime los primeros 10 comentarios del resultado obtenido.\n"
      ],
      "metadata": {
        "id": "78nJMemzn5a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Método 1: Ciclo for convencional\n",
        "\n",
        "#Se crea una lista vacía para almacenar los comentarios sin salto de línea\n",
        "S=[]\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  #Se crea lista vacía para almacenar todos los caracteres del comentario\n",
        "  P=[]\n",
        "\n",
        "  #Ciclo for para todas las letras del cometario actual\n",
        "  for n in docs[i]:\n",
        "\n",
        "    #Si el comentario no es un salto de línea, se añade a la lista\n",
        "    if n != '\\n':\n",
        "      P.append(n)\n",
        "\n",
        "  #Se juntan todos los elementos en un sólo string\n",
        "  L = ''.join(P)\n",
        "\n",
        "  #Se añade el elemento a la lista de comentarios sin salto de línea\n",
        "  S.append(L)\n",
        "\n",
        "#Se imprime la longitud para verificar que se tienen todos los elementos de la lista original\n",
        "print('Los elementos de docs son: {}\\n'.format(len(docs)))\n",
        "print('Los elementos de S son: {}\\n'.format(len(S)))\n",
        "\n",
        "S[0:10]"
      ],
      "metadata": {
        "id": "PwbYYIuZn8pE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b04e201-adcb-4b07-980f-7b6a16302933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los elementos de docs son: 1000\n",
            "\n",
            "Los elementos de S son: 1000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.',\n",
              " 'Crust is not good.',\n",
              " 'Not tasty and the texture was just nasty.',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
              " 'The selection on the menu was great and so were the prices.',\n",
              " 'Now I am getting angry and I want my damn pho.',\n",
              " \"Honeslty it didn't taste THAT fresh.)\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
              " 'The fries were great too.',\n",
              " 'A great touch.']"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Método 2: Lista de comprensión\n",
        "\n",
        "#Se separa el cada comentario por cada generador de espacio y luego se unen los elementos en un sólo string separado por espacios\n",
        "docs_sin_salto = [' '.join(n.split()) for n in docs]\n",
        "\n",
        "#Se imprime la longitud para verificar que se tienen todos los elementos de la lista original\n",
        "print('Los elementos de docs son: {}\\n'.format(len(docs)))\n",
        "print('Los elementos de docs_sin_salto son: {}\\n'.format(len(S)))\n",
        "\n",
        "docs_sin_salto[0:10]"
      ],
      "metadata": {
        "id": "j-0qeh2Jn8l1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc16f345-b49e-4faa-de04-49ebeafd19d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los elementos de docs son: 1000\n",
            "\n",
            "Los elementos de docs_sin_salto son: 1000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.',\n",
              " 'Crust is not good.',\n",
              " 'Not tasty and the texture was just nasty.',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
              " 'The selection on the menu was great and so were the prices.',\n",
              " 'Now I am getting angry and I want my damn pho.',\n",
              " \"Honeslty it didn't taste THAT fresh.)\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
              " 'The fries were great too.',\n",
              " 'A great touch.']"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 2.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan con dos o más signos de admiración seguidos, por ejemplo \"!!!\". \n",
        "\n",
        "Debes imprimir tanto la palabra como la totalidad de signos de admiración que le siguen. \n",
        "\n",
        "Indica cuántos resultados obtuviste.\n",
        "\n"
      ],
      "metadata": {
        "id": "VWeKQC93ctEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "palabras_con_dos_o_mas_signos_de_admiracion = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  #Encontar todas las palabras con dos o más signos de admiración\n",
        "  L = re.findall(r\"\\w+(?:.!!)\", docs[i])\n",
        "\n",
        "  #Revisar si se encontró una palabra o más\n",
        "  if len(L) > 0:\n",
        "\n",
        "    #Añadir todas las palabras encontradas a la lista\n",
        "    for j in range(0,len(L)):\n",
        "      palabras_con_dos_o_mas_signos_de_admiracion.append(L[j])\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras con dos o más signos de admiración encontradas: {}\\n'.format(len(palabras_con_dos_o_mas_signos_de_admiracion)))\n",
        "\n",
        "palabras_con_dos_o_mas_signos_de_admiracion"
      ],
      "metadata": {
        "id": "0p3kMXfddICc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64fa6952-6fa7-469d-815b-267eff0f7563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras con dos o más signos de admiración encontradas: 27\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Firehouse!!!',\n",
              " 'APPETIZERS!!!',\n",
              " 'amazing!!!',\n",
              " 'buffet!!!',\n",
              " 'good!!',\n",
              " 'it!!!',\n",
              " 'DELICIOUS!!',\n",
              " 'amazing!!',\n",
              " 'shawarrrrrrma!!!',\n",
              " 'yucky!!!',\n",
              " 'steak!!!',\n",
              " 'delicious!!!',\n",
              " 'far!!',\n",
              " 'biscuits!!!',\n",
              " 'dry!!',\n",
              " 'disappointing!!!',\n",
              " 'gem !!',\n",
              " 'awesome!!',\n",
              " 'Up!!',\n",
              " 'FLY!!!',\n",
              " 'here!!!',\n",
              " 'great!!!',\n",
              " 'packed!!',\n",
              " 'otherwise!!',\n",
              " 'amazing!!!',\n",
              " 'style!!',\n",
              " 'disappointed!!']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SPVM1MCWdH6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 3.**  \n",
        "\n",
        "Busca e imprime todas las palabras que están escritas totalmente en mayúsculas. Cada coincidencia debe ser una sola palabra.\n",
        "\n",
        "Indica cuántas palabras encontraste.\n",
        "\n"
      ],
      "metadata": {
        "id": "-s3okBqL96TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "todas_las_palabras_en_mayusculas = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  #Separar todas las palabras\n",
        "  palabras = docs[i].split()\n",
        "\n",
        "  #Ciclo for para todas las palabras encontradas\n",
        "  for j in range(0,len(palabras)):\n",
        "\n",
        "    #Quitar todos los caracteres no alfanuméricos, concatenarlos y asignarlos a variable temporal\n",
        "    palabra = ''.join(re.findall(r\"\\w\", palabras[j]))\n",
        "\n",
        "    #Buscar todas las letras máyúsculas de la palabra\n",
        "    letras_mayusculas = ''.join(re.findall(r\"[A-Z]\", palabra))\n",
        "\n",
        "    #Si todas las letras de la palabra son mayúsculas añadir la palabra a la lista\n",
        "    if len(palabra) > 1 and len(palabra) == len(letras_mayusculas):\n",
        "      todas_las_palabras_en_mayusculas.append(palabra)\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras con todas las letras en mayúsculas encontradas: {}\\n'.format(len(todas_las_palabras_en_mayusculas)))\n",
        "\n",
        "todas_las_palabras_en_mayusculas"
      ],
      "metadata": {
        "id": "yKHJkZKo_nW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e249cd-4be1-456f-809f-d1696284f30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras con todas las letras en mayúsculas encontradas: 95\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['THAT',\n",
              " 'APPETIZERS',\n",
              " 'WILL',\n",
              " 'NEVER',\n",
              " 'EVER',\n",
              " 'STEP',\n",
              " 'FORWARD',\n",
              " 'IN',\n",
              " 'IT',\n",
              " 'AGAIN',\n",
              " 'LOVED',\n",
              " 'AND',\n",
              " 'REAL',\n",
              " 'BITCHES',\n",
              " 'NYC',\n",
              " 'STALE',\n",
              " 'DELICIOUS',\n",
              " 'WORST',\n",
              " 'EXPERIENCE',\n",
              " 'EVER',\n",
              " 'ALL',\n",
              " 'BARGAIN',\n",
              " 'NONE',\n",
              " 'FREEZING',\n",
              " 'AYCE',\n",
              " 'FLAVOR',\n",
              " 'NEVER',\n",
              " 'BBQ',\n",
              " 'UNREAL',\n",
              " 'OMG',\n",
              " 'BETTER',\n",
              " 'BLAND',\n",
              " 'RUDE',\n",
              " 'INCONSIDERATE',\n",
              " 'MANAGEMENT',\n",
              " 'WILL',\n",
              " 'NEVER',\n",
              " 'EVER',\n",
              " 'GO',\n",
              " 'BACK',\n",
              " 'AND',\n",
              " 'HAVE',\n",
              " 'TOLD',\n",
              " 'MANY',\n",
              " 'PEOPLE',\n",
              " 'WHAT',\n",
              " 'HAD',\n",
              " 'HAPPENED',\n",
              " 'TOTAL',\n",
              " 'WASTE',\n",
              " 'OF',\n",
              " 'TIME',\n",
              " 'FS',\n",
              " 'AZ',\n",
              " 'LOVED',\n",
              " 'CONCLUSION',\n",
              " 'BEST',\n",
              " 'GO',\n",
              " 'NOW',\n",
              " 'GC',\n",
              " 'AVOID',\n",
              " 'THIS',\n",
              " 'ESTABLISHMENT',\n",
              " 'AN',\n",
              " 'HOUR',\n",
              " 'NASTY',\n",
              " 'OMG',\n",
              " 'NO',\n",
              " 'BEST',\n",
              " 'THE',\n",
              " 'OWNERS',\n",
              " 'REALLY',\n",
              " 'REALLY',\n",
              " 'PERFECT',\n",
              " 'SCREAMS',\n",
              " 'LEGIT',\n",
              " 'MGM',\n",
              " 'BEST',\n",
              " 'FLY',\n",
              " 'FLY',\n",
              " 'FANTASTIC',\n",
              " 'GREAT',\n",
              " 'OK',\n",
              " 'WAY',\n",
              " 'MUST',\n",
              " 'HAVE',\n",
              " 'OK',\n",
              " 'OVERPRICED',\n",
              " 'BARE',\n",
              " 'HANDS',\n",
              " 'WEAK',\n",
              " 'SHOULD',\n",
              " 'RI',\n",
              " 'VERY',\n",
              " 'NOT']"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea un set a partir de las palabras encontradas para eliminar las repeticiones\n",
        "palabras_en_mayusculas = set(todas_las_palabras_en_mayusculas)\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras únicas con todas las letras en mayúsculas encontradas: {}\\n'.format(len(palabras_en_mayusculas)))\n",
        "\n",
        "palabras_en_mayusculas"
      ],
      "metadata": {
        "id": "L3q08aq69sNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d25ae57-49b2-4949-9a48-1d759d475837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras únicas con todas las letras en mayúsculas encontradas: 80\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AGAIN',\n",
              " 'ALL',\n",
              " 'AN',\n",
              " 'AND',\n",
              " 'APPETIZERS',\n",
              " 'AVOID',\n",
              " 'AYCE',\n",
              " 'AZ',\n",
              " 'BACK',\n",
              " 'BARE',\n",
              " 'BARGAIN',\n",
              " 'BBQ',\n",
              " 'BEST',\n",
              " 'BETTER',\n",
              " 'BITCHES',\n",
              " 'BLAND',\n",
              " 'CONCLUSION',\n",
              " 'DELICIOUS',\n",
              " 'ESTABLISHMENT',\n",
              " 'EVER',\n",
              " 'EXPERIENCE',\n",
              " 'FANTASTIC',\n",
              " 'FLAVOR',\n",
              " 'FLY',\n",
              " 'FORWARD',\n",
              " 'FREEZING',\n",
              " 'FS',\n",
              " 'GC',\n",
              " 'GO',\n",
              " 'GREAT',\n",
              " 'HAD',\n",
              " 'HANDS',\n",
              " 'HAPPENED',\n",
              " 'HAVE',\n",
              " 'HOUR',\n",
              " 'IN',\n",
              " 'INCONSIDERATE',\n",
              " 'IT',\n",
              " 'LEGIT',\n",
              " 'LOVED',\n",
              " 'MANAGEMENT',\n",
              " 'MANY',\n",
              " 'MGM',\n",
              " 'MUST',\n",
              " 'NASTY',\n",
              " 'NEVER',\n",
              " 'NO',\n",
              " 'NONE',\n",
              " 'NOT',\n",
              " 'NOW',\n",
              " 'NYC',\n",
              " 'OF',\n",
              " 'OK',\n",
              " 'OMG',\n",
              " 'OVERPRICED',\n",
              " 'OWNERS',\n",
              " 'PEOPLE',\n",
              " 'PERFECT',\n",
              " 'REAL',\n",
              " 'REALLY',\n",
              " 'RI',\n",
              " 'RUDE',\n",
              " 'SCREAMS',\n",
              " 'SHOULD',\n",
              " 'STALE',\n",
              " 'STEP',\n",
              " 'THAT',\n",
              " 'THE',\n",
              " 'THIS',\n",
              " 'TIME',\n",
              " 'TOLD',\n",
              " 'TOTAL',\n",
              " 'UNREAL',\n",
              " 'VERY',\n",
              " 'WASTE',\n",
              " 'WAY',\n",
              " 'WEAK',\n",
              " 'WHAT',\n",
              " 'WILL',\n",
              " 'WORST'}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 4.**  \n",
        "\n",
        "Busca e imprime los comentarios en donde todos los caracteres alfabéticos (letras) están en mayúsculas. \n",
        "\n",
        "Cada coincidencia encontrada debe ser todo el comentario/enunciado.\n",
        "\n",
        "Indica cuántos resultados obtuviste.\n"
      ],
      "metadata": {
        "id": "GX8eYyDoMZma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "comentarios_en_mayusculas = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs_sin_salto)):\n",
        "\n",
        "  #Separar todas las palabras\n",
        "  comentario = docs_sin_salto[i]\n",
        "\n",
        "  #Quitar todos los caracteres no alfanuméricos, concatenarlos y asignarlos a variable temporal\n",
        "  alfanumericos_totales = ''.join(re.findall(r\"\\w\", comentario))\n",
        "\n",
        "  #Buscar todas las letras máyúsculas de la palabra\n",
        "  alfanumericos_totales_mayusculas = ''.join(re.findall(r\"[A-Z]\", comentario))\n",
        "\n",
        "  #Si todas las letras de la palabra son mayúsculas añadir la palabra a la lista\n",
        "  if len(comentario) > 0 and len(alfanumericos_totales) == len(alfanumericos_totales_mayusculas):\n",
        "    comentarios_en_mayusculas.append(comentario)\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Comentarios con todas las letras en mayúsculas encontrados: {}\\n'.format(len(comentarios_en_mayusculas)))\n",
        "\n",
        "comentarios_en_mayusculas"
      ],
      "metadata": {
        "id": "K8VuZxvTMYj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f3404ab-7d5f-4624-faf0-5662e3f96008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comentarios con todas las letras en mayúsculas encontrados: 5\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DELICIOUS!!',\n",
              " 'RUDE & INCONSIDERATE MANAGEMENT.',\n",
              " 'WILL NEVER EVER GO BACK AND HAVE TOLD MANY PEOPLE WHAT HAD HAPPENED.',\n",
              " 'TOTAL WASTE OF TIME.',\n",
              " 'AVOID THIS ESTABLISHMENT!']"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PmKgX7sCMcDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 5.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una vocal acentuada, del tipo á, é, í, ó, ú. \n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "a1i6qv7-McmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "palabras_con_acentos = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  comentario = docs[i]\n",
        "\n",
        "  #Separar por espacios y caracteres no alfanumericos para aislar sólo las palabras\n",
        "  palabras = re.split(r' |-|,|[.]|;|:|¡|!|[\"]|[¿]|[?]|[/]|[(]|[)]', comentario)\n",
        "\n",
        "  for j in range(0,len(palabras)):\n",
        "\n",
        "    #Encontar todos los acentos\n",
        "    acentos = re.findall(r\"[áéíóúÁÉÍÓÚ]\", palabras[j])\n",
        "\n",
        "    #Si se encontró uno más acentos añadir palabra a la lista\n",
        "    if len(acentos) > 0:\n",
        "\n",
        "      #Quitar caracteres no alfanuméricos\n",
        "      palabras_con_acentos.append(palabras[j])\n",
        "\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras con acentos encontradas: {}\\n'.format(len(palabras_con_acentos)))\n",
        "\n",
        "palabras_con_acentos"
      ],
      "metadata": {
        "id": "nZZ5zKUOMeGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab10c89-f907-4996-af37-d797e73170a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras con acentos encontradas: 3\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fiancé', 'Café', 'puréed']"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l1mFvUEZMe8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 6.**  \n",
        "\n",
        "Busca e imprime todas las cantidades numéricas monetarias, enteras o con decimales, que inician con el símbolo $\\$$. \n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "ZmPiAI82Mfb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "cantidades_monetarias = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  comentario = docs[i]\n",
        "\n",
        "  palabras = comentario.split()\n",
        "\n",
        "  for j in range(0,len(palabras)):\n",
        "\n",
        "    #Encontar todas las cantidades monetarias\n",
        "    cantidad_monetaria = re.findall(r\"[$]+(?:.{0,}|\\d{0,})+(?:\\d{1,})\", palabras[j])\n",
        "    #cantidad_monetaria = re.findall(r\"[$]\", palabras[j])\n",
        "\n",
        "    #Si se encontró una o más cantidades monetarias añadir palabra a la lista\n",
        "    if len(cantidad_monetaria) > 0:\n",
        "\n",
        "      cantidades_monetarias.append(cantidad_monetaria[0])\n",
        "\n",
        "\n",
        "#Se imprime la longitud para contar todas las cantidades monetarias encontradas\n",
        "print('Cantidades monetarias encontradas: {}\\n'.format(len(cantidades_monetarias)))\n",
        "\n",
        "cantidades_monetarias"
      ],
      "metadata": {
        "id": "6vhe9-Y-MhL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80c9e1a-9da5-4209-f19b-2b689a61814c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidades monetarias encontradas: 8\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['$20', '$4.00', '$17', '$3', '$35', '$7.85', '$12', '$11.99']"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_t0a5xWDMhQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 7.**  \n",
        "\n",
        "Busca e imprime todas las palabras que sean variantes de la palabra \"love\", sin importar si incluyen mayúsculas o minúsculas, o la manera en que esté conjugada o alguna otra variación que se haga con dicha palabra.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "2j-HpvhwMhq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "palabras_con_love = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  comentario = docs[i]\n",
        "\n",
        "  #Separar por espacios y caracteres no alfanumericos para aislar sólo las palabras\n",
        "  palabras = re.split(r' |-|,|[.]|;|:|¡|!|[\"]|[¿]|[?]|[/]|[(]|[)]', comentario)\n",
        "\n",
        "  for j in range(0,len(palabras)):\n",
        "\n",
        "    #Encontar todas las variantes de love\n",
        "    love = re.findall(r\"\\b(?:lo+v)\", palabras[j].lower())\n",
        "\n",
        "    #Si se encontraron palabras, añadirlas a la lista\n",
        "    if len(love) > 0:\n",
        "\n",
        "      #Quitar caracteres no alfanuméricos\n",
        "      palabras_con_love.append(palabras[j])\n",
        "\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras con love encontradas: {}\\n'.format(len(palabras_con_love)))\n",
        "\n",
        "palabras_con_love"
      ],
      "metadata": {
        "id": "kqqyRChVMjol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c8d028-057a-4fa0-f0af-e6ae78fcaeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras con love encontradas: 36\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Loved',\n",
              " 'loved',\n",
              " 'Loved',\n",
              " 'love',\n",
              " 'loves',\n",
              " 'LOVED',\n",
              " 'lovers',\n",
              " 'loving',\n",
              " 'love',\n",
              " 'lovers',\n",
              " 'Love',\n",
              " 'loved',\n",
              " 'loved',\n",
              " 'love',\n",
              " 'love',\n",
              " 'love',\n",
              " 'loved',\n",
              " 'love',\n",
              " 'loved',\n",
              " 'Love',\n",
              " 'LOVED',\n",
              " 'love',\n",
              " 'lovely',\n",
              " 'love',\n",
              " 'lovely',\n",
              " 'love',\n",
              " 'lover',\n",
              " 'loved',\n",
              " 'love',\n",
              " 'love',\n",
              " 'love',\n",
              " 'love',\n",
              " 'love',\n",
              " 'love',\n",
              " 'love',\n",
              " 'love']"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UXd0VQluMj_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 8.**  \n",
        "\n",
        "Busca e imprime todas las palabras, variantes de \"so\" y \"good\", que tengan dos o más \"o\" en \"so\" y 3 o más \"o\" en good. \n",
        "\n",
        "Indica cuántas encontraste.\n"
      ],
      "metadata": {
        "id": "Ctb-NTY3MkYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "palabras_con_so_y_good = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  comentario = docs[i]\n",
        "\n",
        "  #Separar por espacios y caracteres no alfanumericos para aislar sólo las palabras\n",
        "  palabras = re.split(r' |-|,|[.]|;|:|¡|!|[\"]|[¿]|[?]|[/]|[(]|[)]', comentario)\n",
        "\n",
        "  for j in range(0,len(palabras)):\n",
        "\n",
        "    #Encontar todas las variantes de so y good\n",
        "    so = re.findall(r\"so{2,}\\b\", palabras[j].lower())\n",
        "    good = re.findall(r\"go{3,}d+\\w\\b\", palabras[j].lower())\n",
        "\n",
        "    #Si se encontraron palabras, añadirlas a la lista\n",
        "    if len(so) > 0 or len(good) > 0:\n",
        "\n",
        "      #Quitar caracteres no alfanuméricos\n",
        "      palabras_con_so_y_good.append(palabras[j])\n",
        "\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras con so y good encontradas: {}\\n'.format(len(palabras_con_so_y_good)))\n",
        "\n",
        "palabras_con_so_y_good"
      ],
      "metadata": {
        "id": "A8Nf3B_cMlqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1362d5-1195-41fd-e5e7-0f4bf6297e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras con so y good encontradas: 5\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sooooo', 'soooo', 'gooodd', 'soooooo', 'soooo']"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "svS4-vvPMl6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 9.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una longitud mayor estrictamente a 10 caracteres alfabéticos.\n",
        "\n",
        "No se consideran los signos de puntuación o caracteres especiales en la longitud de estas cadenas, solo caracteres alfabéticos en mayúsculas o minúsculas.\n",
        "\n",
        "Indica la cantidad de palabras encontradas.\n"
      ],
      "metadata": {
        "id": "hkak1opjMmlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "palabras_mayores_a_10_caracteres = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  comentario = docs[i]\n",
        "\n",
        "  #Separar por espacios y caracteres no alfanumericos para aislar sólo las palabras\n",
        "  palabras = re.split(r' |-|,|[.]|;|:|¡|!|[\"]|[¿]|[?]|[/]|[(]|[)]', comentario)\n",
        "\n",
        "  for j in range(0,len(palabras)):\n",
        "\n",
        "    #Si la palabra es más larga que 10 caracteres, añadirla a la lista\n",
        "    if len(palabras[j]) > 10:\n",
        "      \n",
        "      palabras_mayores_a_10_caracteres.append(palabras[j])\n",
        "\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras palabras mayores a 10 caracteres encontradas: {}\\n'.format(len(palabras_mayores_a_10_caracteres)))\n",
        "\n",
        "palabras_mayores_a_10_caracteres"
      ],
      "metadata": {
        "id": "PYxdp3uhMoD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c065d09-4295-4c42-eee3-7c0c7adba9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras palabras mayores a 10 caracteres encontradas: 143\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['recommendation',\n",
              " 'recommended',\n",
              " 'overwhelmed',\n",
              " 'inexpensive',\n",
              " 'establishment',\n",
              " 'imaginative',\n",
              " 'opportunity',\n",
              " 'experiencing',\n",
              " 'underwhelming',\n",
              " 'relationship',\n",
              " 'unsatisfying',\n",
              " 'disappointing',\n",
              " 'outrageously',\n",
              " 'disappointing',\n",
              " 'expectations',\n",
              " 'restaurants',\n",
              " 'suggestions',\n",
              " 'disappointed',\n",
              " 'considering',\n",
              " 'Unfortunately',\n",
              " 'immediately',\n",
              " 'ingredients',\n",
              " 'accommodations',\n",
              " 'maintaining',\n",
              " 'Interesting',\n",
              " 'disrespected',\n",
              " 'accordingly',\n",
              " 'unbelievable',\n",
              " 'cheeseburger',\n",
              " 'descriptions',\n",
              " 'inexpensive',\n",
              " 'disappointed',\n",
              " 'Veggitarian',\n",
              " 'outstanding',\n",
              " 'recommendation',\n",
              " 'disappointed',\n",
              " 'disappointed',\n",
              " 'neighborhood',\n",
              " 'disappointed',\n",
              " 'corporation',\n",
              " 'considering',\n",
              " 'exceptional',\n",
              " 'shawarrrrrrma',\n",
              " 'disappointed',\n",
              " 'vinaigrette',\n",
              " 'immediately',\n",
              " 'unbelievably',\n",
              " 'replenished',\n",
              " 'disappointed',\n",
              " 'enthusiastic',\n",
              " 'Outstanding',\n",
              " 'comfortable',\n",
              " 'interesting',\n",
              " 'INCONSIDERATE',\n",
              " 'considering',\n",
              " 'transcendant',\n",
              " 'disappointment',\n",
              " 'disappointed',\n",
              " 'disappointed',\n",
              " 'overwhelmed',\n",
              " 'professional',\n",
              " 'Furthermore',\n",
              " 'combination',\n",
              " 'connoisseur',\n",
              " 'profiterole',\n",
              " 'outstanding',\n",
              " 'acknowledged',\n",
              " 'ventilation',\n",
              " 'beautifully',\n",
              " 'establishment',\n",
              " 'extraordinary',\n",
              " 'disappointed',\n",
              " 'cheesecurds',\n",
              " 'disappointed',\n",
              " 'interesting',\n",
              " 'experienced',\n",
              " 'opportunity',\n",
              " 'disgraceful',\n",
              " 'restaurants',\n",
              " 'ESTABLISHMENT',\n",
              " 'recommended',\n",
              " 'disappointed',\n",
              " 'recommended',\n",
              " 'acknowledged',\n",
              " 'presentation',\n",
              " 'Philadelphia',\n",
              " 'disappointed',\n",
              " 'disappointing',\n",
              " 'grandmother',\n",
              " 'drastically',\n",
              " 'informative',\n",
              " 'Disappointed',\n",
              " 'constructed',\n",
              " 'comfortable',\n",
              " 'Smashburger',\n",
              " 'cheeseburger',\n",
              " 'neighborhood',\n",
              " 'disappointed',\n",
              " 'hospitality',\n",
              " 'recommending',\n",
              " 'disappointed',\n",
              " 'deliciously',\n",
              " 'compliments',\n",
              " 'recommendation',\n",
              " 'establishment',\n",
              " 'calligraphy',\n",
              " 'traditional',\n",
              " 'combination',\n",
              " \"girlfriend's\",\n",
              " 'Unfortunately',\n",
              " 'Wienerschnitzel',\n",
              " 'unfortunately',\n",
              " 'considering',\n",
              " \"Caballero's\",\n",
              " 'highlighted',\n",
              " 'Mediterranean',\n",
              " 'unprofessional',\n",
              " 'anticipated',\n",
              " 'disappointing',\n",
              " 'unexperienced',\n",
              " 'disrespected',\n",
              " 'professional',\n",
              " 'restaurants',\n",
              " 'Disappointing',\n",
              " 'WAAAAAAyyyyyyyyyy',\n",
              " 'reservation',\n",
              " 'imagination',\n",
              " 'undercooked',\n",
              " 'disappointed',\n",
              " 'disappointment',\n",
              " 'disappointment',\n",
              " 'deuchebaggery',\n",
              " 'disappointed',\n",
              " 'disappointment',\n",
              " 'immediately',\n",
              " 'Unfortunately',\n",
              " 'disapppointment',\n",
              " 'circumstances',\n",
              " 'undercooked',\n",
              " 'caterpillar',\n",
              " 'presentation',\n",
              " 'disappointed',\n",
              " 'underwhelming']"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BR7e2F4FMof-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 10.**  \n",
        "\n",
        "Busca e imprime todas las palabras que inician con una letra mayúscula y terminan con una minúscula, pero que además no sea la primera palabra del comentario/string. \n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ],
      "metadata": {
        "id": "ApjTNzSxMpDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "palabras_con_mayuscula_y_minuscula = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  comentario = docs[i]\n",
        "\n",
        "  #Separar por espacios y caracteres no alfanumericos para aislar sólo las palabras\n",
        "  palabras = re.split(r' |,|[.]|;|:|¡|!|[¿]|[?]|[/]|[(]|[)]', comentario)\n",
        "\n",
        "  #Se comienza por la segunda palabra del comentario\n",
        "  for j in range(1,len(palabras)):\n",
        "\n",
        "    #Encontar todas las palabras con mayúscula y mínuscula al final\n",
        "    mayuscula_y_minuscula = re.findall(r\"[A-Z]+[a-z]\", palabras[j])\n",
        "\n",
        "    #Si se encontraron palabras, añadirlas a la lista\n",
        "    if len(mayuscula_y_minuscula) > 0:\n",
        "\n",
        "      #Quitar caracteres no alfanuméricos\n",
        "      palabras_con_mayuscula_y_minuscula.append(palabras[j].replace('\"',''))\n",
        "\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras con mayuscula y minuscula encontradas: {}\\n'.format(len(palabras_con_mayuscula_y_minuscula)))\n",
        "\n",
        "palabras_con_mayuscula_y_minuscula"
      ],
      "metadata": {
        "id": "Vb0ndRGAMqdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ede6f6-7221-46b3-e4d6-77834379fde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras con mayuscula y minuscula encontradas: 274\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Loved',\n",
              " 'May',\n",
              " 'Rick',\n",
              " 'Steve',\n",
              " 'Cape',\n",
              " 'Cod',\n",
              " 'Vegas',\n",
              " 'Burrittos',\n",
              " 'Blah',\n",
              " 'The',\n",
              " 'They',\n",
              " 'Mexican',\n",
              " 'Luke',\n",
              " 'Our',\n",
              " 'Hiro',\n",
              " 'Firehouse',\n",
              " 'Greek',\n",
              " 'Greek',\n",
              " 'Heart',\n",
              " 'Attack',\n",
              " 'Grill',\n",
              " 'Vegas',\n",
              " 'Dos',\n",
              " 'Gringos',\n",
              " 'Jeff',\n",
              " 'Really',\n",
              " 'Excalibur',\n",
              " 'Very',\n",
              " 'Bad',\n",
              " 'Customer',\n",
              " 'Service',\n",
              " 'Vegas',\n",
              " 'Rice',\n",
              " 'Company',\n",
              " 'Pho',\n",
              " 'Hard',\n",
              " 'Rock',\n",
              " 'Casino',\n",
              " 'Buffet',\n",
              " 'Tigerlilly',\n",
              " 'Yama',\n",
              " 'Thai',\n",
              " 'Indian',\n",
              " 'Not',\n",
              " 'Vegas',\n",
              " 'Lox',\n",
              " 'Subway',\n",
              " 'Subway',\n",
              " 'Vegas',\n",
              " 'Vegas',\n",
              " 'Mandalay',\n",
              " 'Bay',\n",
              " 'Great',\n",
              " 'Voodoo',\n",
              " 'Phoenix',\n",
              " 'Vegas',\n",
              " 'Khao',\n",
              " 'Soi',\n",
              " 'Lemon',\n",
              " \"Joey's\",\n",
              " 'Valley',\n",
              " 'Phoenix',\n",
              " 'Magazine',\n",
              " 'Pho',\n",
              " 'Fridays',\n",
              " 'Tasty',\n",
              " 'Jamaican',\n",
              " 'Bisque',\n",
              " 'Bussell',\n",
              " 'Sprouts',\n",
              " 'Risotto',\n",
              " 'Filet',\n",
              " 'Otto',\n",
              " 'Yeah',\n",
              " 'Honestly',\n",
              " 'Not',\n",
              " 'It',\n",
              " 'Also',\n",
              " 'Vegas',\n",
              " 'Greek',\n",
              " 'Vegas',\n",
              " 'Veggitarian',\n",
              " 'Madison',\n",
              " 'Ironman',\n",
              " 'Jenni',\n",
              " 'Pho',\n",
              " 'Bachi',\n",
              " 'Burger',\n",
              " 'Pizza',\n",
              " 'Salads',\n",
              " 'They',\n",
              " 'Yelpers',\n",
              " 'Bachi',\n",
              " 'Service-check',\n",
              " 'English',\n",
              " 'Pizza',\n",
              " 'Hut',\n",
              " 'Seat',\n",
              " 'Gold',\n",
              " 'Standard',\n",
              " 'Thai',\n",
              " 'Tucson',\n",
              " 'Vegas',\n",
              " 'Chipotle',\n",
              " 'Baseball',\n",
              " 'Gordon',\n",
              " \"Ramsey's\",\n",
              " 'Steak',\n",
              " 'Vegas',\n",
              " 'The',\n",
              " 'Outstanding',\n",
              " 'Best',\n",
              " 'Food',\n",
              " 'Lobster',\n",
              " 'Bisque',\n",
              " 'Vegas',\n",
              " 'Eggplant',\n",
              " 'Green',\n",
              " 'Bean',\n",
              " 'Halibut',\n",
              " 'Vegas',\n",
              " 'Vegas',\n",
              " 'Vegas',\n",
              " 'Crystals',\n",
              " 'Aria',\n",
              " 'Ians',\n",
              " 'Bouchon',\n",
              " 'San',\n",
              " 'Francisco',\n",
              " 'Bay',\n",
              " 'Area',\n",
              " 'Buldogis',\n",
              " 'Gourmet',\n",
              " 'Hot',\n",
              " 'Dog',\n",
              " 'Steiners',\n",
              " \"Carly's\",\n",
              " 'Vegas',\n",
              " 'Camelback',\n",
              " 'Flower',\n",
              " 'Shop',\n",
              " 'Cartel',\n",
              " 'Coffee',\n",
              " 'Las',\n",
              " 'Vegas',\n",
              " 'Bunch',\n",
              " 'Very',\n",
              " \"Mom's\",\n",
              " 'Noca',\n",
              " 'Vegas',\n",
              " 'Sat',\n",
              " 'Sun',\n",
              " 'Mexican',\n",
              " 'Frenchman',\n",
              " 'Perfect',\n",
              " 'Vegas',\n",
              " 'Palm',\n",
              " 'Are',\n",
              " 'This',\n",
              " 'Thai',\n",
              " 'Toast',\n",
              " 'Thai',\n",
              " 'Phoenix',\n",
              " 'Crema',\n",
              " 'Café',\n",
              " 'Philadelphia',\n",
              " 'North',\n",
              " 'Scottsdale',\n",
              " 'Bloody',\n",
              " 'Mary',\n",
              " 'Pho',\n",
              " 'Caesar',\n",
              " 'Macarons',\n",
              " 'Experience',\n",
              " 'Very',\n",
              " 'Disappointed',\n",
              " 'Big',\n",
              " 'Bay',\n",
              " 'Plater',\n",
              " 'Italian',\n",
              " 'Vegas',\n",
              " 'Baba',\n",
              " 'Ganoush',\n",
              " 'Nobu',\n",
              " 'Smashburger',\n",
              " 'Panna',\n",
              " 'Cotta',\n",
              " 'Breeze',\n",
              " 'Mango',\n",
              " 'Magic',\n",
              " 'Pineapple',\n",
              " 'Delight',\n",
              " 'The',\n",
              " 'Strip',\n",
              " 'Steak',\n",
              " 'Paradise',\n",
              " 'Valley',\n",
              " 'Cibo',\n",
              " 'Thumbs',\n",
              " 'Up',\n",
              " 'Italian',\n",
              " 'Pros',\n",
              " 'Large',\n",
              " 'Nice',\n",
              " 'Great',\n",
              " 'The',\n",
              " 'Elk',\n",
              " 'Filet',\n",
              " 'Dylan',\n",
              " 'All',\n",
              " 'Han',\n",
              " 'Nan',\n",
              " 'Chicken',\n",
              " 'Bar',\n",
              " 'Edinburgh',\n",
              " 'Chinese',\n",
              " 'Indian',\n",
              " 'Chinese',\n",
              " 'Prices',\n",
              " 'Phoenix',\n",
              " 'Both',\n",
              " 'Hot',\n",
              " 'Sour',\n",
              " 'Egg',\n",
              " 'Flower',\n",
              " 'Soups',\n",
              " 'Stars',\n",
              " 'Sunday',\n",
              " 'Hunan',\n",
              " 'The',\n",
              " 'Pita',\n",
              " 'Wienerschnitzel',\n",
              " 'Maine',\n",
              " 'Lobster',\n",
              " 'Roll',\n",
              " 'Kabuki',\n",
              " 'Maria',\n",
              " \"Caballero's\",\n",
              " 'Wife',\n",
              " 'Everything',\n",
              " 'Strip',\n",
              " \"Costco's\",\n",
              " 'To',\n",
              " 'Place',\n",
              " 'Gyros',\n",
              " 'Japanese',\n",
              " 'Albondigas',\n",
              " 'Mediterranean',\n",
              " 'Chicken',\n",
              " 'Salad',\n",
              " 'Mellow',\n",
              " 'Mushroom',\n",
              " 'Thai',\n",
              " 'Vegas',\n",
              " 'Mmmm',\n",
              " 'Buffet',\n",
              " 'Bellagio',\n",
              " 'Vegas',\n",
              " 'Christmas',\n",
              " 'Eve',\n",
              " \"Denny's\",\n",
              " 'Vegetarian',\n",
              " 'Taco',\n",
              " 'Heimer',\n",
              " 'Ha',\n",
              " 'Long',\n",
              " 'Bay',\n",
              " 'Subway',\n",
              " 'When',\n",
              " 'Brushfire',\n",
              " 'Mirage',\n",
              " 'In',\n",
              " 'Ninja',\n",
              " 'Sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dLPTRPnTMqqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 11.**  \n",
        "\n",
        "Busca e imprime la secuencia de dos o más palabras que están separadas por un guion, \"-\", sin que tengan espacios en blanco entre ellas.\n",
        "\n",
        "Por ejemplo \"Go-Kart\" sería válido, pero \"Go  -Kart\" o \"Go  -  Kart\" no lo serían. \n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ],
      "metadata": {
        "id": "u7nfm4KhMrNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "palabras_separadas_por_guion = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  comentario = docs[i]\n",
        "\n",
        "  #Separar por espacios y caracteres no alfanumericos para aislar sólo las palabras\n",
        "  palabras = re.split(r' |,|[.]|;|:|¡|!|[¿]|[?]|[/]|[(]|[)]', comentario)\n",
        "\n",
        "  #Se comienza por la segunda palabra del comentario\n",
        "  for j in range(0,len(palabras)):\n",
        "\n",
        "    #Encontar todas las palabras separadas por un guión\n",
        "    palabra_separada_por_guion = re.findall(r\"[a-z|A-Z]+[-]+(?:[a-z|A-Z]{1,})\", palabras[j])\n",
        "\n",
        "    #Si se encontraron palabras, añadirlas a la lista\n",
        "    if len(palabra_separada_por_guion) > 0:\n",
        "\n",
        "      #Ciclo en caso de que hayan más de una coincidencia en una sola palabra\n",
        "      for k in range(0, len(palabra_separada_por_guion)):\n",
        "        #Quitar caracteres no alfanuméricos\n",
        "        palabras_separadas_por_guion.append(palabra_separada_por_guion[k])\n",
        "\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras palabras separadas por guion encontradas: {}\\n'.format(len(palabras_separadas_por_guion)))\n",
        "\n",
        "palabras_separadas_por_guion"
      ],
      "metadata": {
        "id": "OwU-a7eGMsub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75a5cb6-c2fe-41a0-9702-9925383d8c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras palabras separadas por guion encontradas: 21\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['flat-lined',\n",
              " 'hands-down',\n",
              " 'must-stop',\n",
              " 'sub-par',\n",
              " 'Service-check',\n",
              " 'in-house',\n",
              " 'been-stepped',\n",
              " 'in-and',\n",
              " 'tracked-everywhere',\n",
              " 'multi-grain',\n",
              " 'to-go',\n",
              " 'non-customer',\n",
              " 'High-quality',\n",
              " 'sit-down',\n",
              " 'over-whelm',\n",
              " 'low-key',\n",
              " 'non-fancy',\n",
              " 'golden-crispy',\n",
              " 'over-priced',\n",
              " 'over-hip',\n",
              " 'under-services']"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SgzIL74ZMtGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 12.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan en \"ing\" o \"ed\". \n",
        "\n",
        "Indica la cantidad de palabras que encontraste de cada una."
      ],
      "metadata": {
        "id": "DEIgl79HMthr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar las palabras\n",
        "palabras_que_terminan_con_ing = []\n",
        "palabras_que_terminan_con_ed = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  comentario = docs[i]\n",
        "\n",
        "  #Separar por espacios y caracteres no alfanumericos para aislar sólo las palabras\n",
        "  palabras = re.split(r' |-|,|[.]|;|:|¡|!|[\"]|[¿]|[?]|[/]|[(]|[)]', comentario)\n",
        "\n",
        "  #Se comienza por la segunda palabra del comentario\n",
        "  for j in range(0,len(palabras)):\n",
        "\n",
        "    #Encontar todas las palabras que terminan con ing\n",
        "    ing = re.findall(r\"[a-z|A-Z]+(?:ing)\\b\", palabras[j])\n",
        "\n",
        "    #Encontar todas las palabras que terminan con ed\n",
        "    ed = re.findall(r\"[a-z|A-Z]+(?:ed)\\b\", palabras[j])\n",
        "\n",
        "    #Si se encontraron palabras, añadirlas a la lista\n",
        "    if len(ing) > 0:\n",
        "\n",
        "      #Quitar caracteres no alfanuméricos\n",
        "      palabras_que_terminan_con_ing.append(ing[0])\n",
        "\n",
        "    if len(ed) > 0:\n",
        "\n",
        "      #Quitar caracteres no alfanuméricos\n",
        "      palabras_que_terminan_con_ed.append(ed[0])\n",
        "\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras que_terminan con ing encontradas: {}\\n'.format(len(palabras_que_terminan_con_ing)))\n",
        "\n",
        "#Se imprime la longitud para contar todas las palabras encontradas\n",
        "print('Palabras que_terminan con ed encontradas: {}\\n'.format(len(palabras_que_terminan_con_ed)))\n",
        "\n",
        "palabras_que_terminan_con_ing_ed = palabras_que_terminan_con_ing\n",
        "\n",
        "palabras_que_terminan_con_ing_ed.append(palabras_que_terminan_con_ed)\n",
        "\n",
        "palabras_que_terminan_con_ing_ed"
      ],
      "metadata": {
        "id": "I4TSofBMMv9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37946dcc-8fee-4411-cdee-e24091b188ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que_terminan con ing encontradas: 279\n",
            "\n",
            "Palabras que_terminan con ed encontradas: 334\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['during',\n",
              " 'getting',\n",
              " 'being',\n",
              " 'being',\n",
              " 'amazing',\n",
              " 'running',\n",
              " 'redeeming',\n",
              " 'getting',\n",
              " 'thing',\n",
              " 'dressing',\n",
              " 'refreshing',\n",
              " 'running',\n",
              " 'amazing',\n",
              " 'nothing',\n",
              " 'appalling',\n",
              " 'wasting',\n",
              " 'eating',\n",
              " 'going',\n",
              " 'Coming',\n",
              " 'experiencing',\n",
              " 'underwhelming',\n",
              " 'eating',\n",
              " 'raving',\n",
              " 'spring',\n",
              " 'unsatisfying',\n",
              " 'amazing',\n",
              " 'Everything',\n",
              " 'disappointing',\n",
              " 'dining',\n",
              " 'flirting',\n",
              " 'thing',\n",
              " 'coming',\n",
              " 'playing',\n",
              " 'ordering',\n",
              " 'arriving',\n",
              " 'disappointing',\n",
              " 'preparing',\n",
              " 'loving',\n",
              " 'liking',\n",
              " 'reviewing',\n",
              " 'venturing',\n",
              " 'including',\n",
              " 'during',\n",
              " 'changing',\n",
              " 'going',\n",
              " 'considering',\n",
              " 'coming',\n",
              " 'going',\n",
              " 'everything',\n",
              " 'looking',\n",
              " 'dressing',\n",
              " 'dining',\n",
              " 'Everything',\n",
              " 'amazing',\n",
              " 'judging',\n",
              " 'maintaining',\n",
              " 'asking',\n",
              " 'having',\n",
              " 'something',\n",
              " 'lacking',\n",
              " 'Interesting',\n",
              " 'preparing',\n",
              " 'missing',\n",
              " 'feeling',\n",
              " 'exceeding',\n",
              " 'inviting',\n",
              " 'climbing',\n",
              " 'waiting',\n",
              " 'coming',\n",
              " 'being',\n",
              " 'lacking',\n",
              " 'going',\n",
              " 'amazing',\n",
              " 'dealing',\n",
              " 'annoying',\n",
              " 'falling',\n",
              " 'sporting',\n",
              " 'amazing',\n",
              " 'providing',\n",
              " 'building',\n",
              " 'lighting',\n",
              " 'going',\n",
              " 'nothing',\n",
              " 'working',\n",
              " 'eating',\n",
              " 'dressing',\n",
              " 'being',\n",
              " 'outstanding',\n",
              " 'getting',\n",
              " 'amazing',\n",
              " 'rating',\n",
              " 'eating',\n",
              " 'writing',\n",
              " 'everything',\n",
              " 'dining',\n",
              " 'boring',\n",
              " 'charming',\n",
              " 'going',\n",
              " 'making',\n",
              " 'pricing',\n",
              " 'considering',\n",
              " 'amazing',\n",
              " 'Everything',\n",
              " 'nothing',\n",
              " 'nothing',\n",
              " 'driving',\n",
              " 'during',\n",
              " 'evening',\n",
              " 'Outstanding',\n",
              " 'buying',\n",
              " 'handling',\n",
              " 'wasting',\n",
              " 'craving',\n",
              " 'dining',\n",
              " 'interesting',\n",
              " 'amazing',\n",
              " 'being',\n",
              " 'outshining',\n",
              " 'starving',\n",
              " 'coming',\n",
              " 'considering',\n",
              " 'shopping',\n",
              " 'nothing',\n",
              " 'getting',\n",
              " 'trying',\n",
              " 'eating',\n",
              " 'going',\n",
              " 'everything',\n",
              " 'Nothing',\n",
              " 'going',\n",
              " 'outstanding',\n",
              " 'running',\n",
              " 'forgetting',\n",
              " 'upgrading',\n",
              " 'eating',\n",
              " 'bring',\n",
              " 'hoping',\n",
              " 'living',\n",
              " 'dining',\n",
              " 'filling',\n",
              " 'amazing',\n",
              " 'Everything',\n",
              " 'thing',\n",
              " 'amazing',\n",
              " 'Everything',\n",
              " 'interesting',\n",
              " 'amazing',\n",
              " 'amazing',\n",
              " 'waiting',\n",
              " 'going',\n",
              " 'going',\n",
              " 'dining',\n",
              " 'saving',\n",
              " 'something',\n",
              " 'trying',\n",
              " 'disgusting',\n",
              " 'hankering',\n",
              " 'being',\n",
              " 'being',\n",
              " 'being',\n",
              " 'setting',\n",
              " 'sitting',\n",
              " 'waiting',\n",
              " 'satisfying',\n",
              " 'eating',\n",
              " 'being',\n",
              " 'freaking',\n",
              " 'getting',\n",
              " 'amazing',\n",
              " 'disappointing',\n",
              " 'seasoning',\n",
              " 'going',\n",
              " 'being',\n",
              " 'bring',\n",
              " 'letting',\n",
              " 'evening',\n",
              " 'waiting',\n",
              " 'being',\n",
              " 'eating',\n",
              " 'going',\n",
              " 'seating',\n",
              " 'playing',\n",
              " 'amazing',\n",
              " 'staying',\n",
              " 'giving',\n",
              " 'talking',\n",
              " 'amazing',\n",
              " 'amazing',\n",
              " 'amazing',\n",
              " 'amazing',\n",
              " 'filling',\n",
              " 'dripping',\n",
              " 'going',\n",
              " 'serving',\n",
              " 'recommending',\n",
              " 'thing',\n",
              " 'reading',\n",
              " 'seating',\n",
              " 'going',\n",
              " 'everything',\n",
              " 'thing',\n",
              " 'sitting',\n",
              " 'waiting',\n",
              " 'bring',\n",
              " 'revisiting',\n",
              " 'coming',\n",
              " 'anything',\n",
              " 'feeling',\n",
              " 'during',\n",
              " 'thing',\n",
              " 'being',\n",
              " 'amazing',\n",
              " 'being',\n",
              " 'amazing',\n",
              " 'satifying',\n",
              " 'describing',\n",
              " 'coming',\n",
              " 'everything',\n",
              " 'Paying',\n",
              " 'going',\n",
              " 'thing',\n",
              " 'amazing',\n",
              " 'getting',\n",
              " 'cramming',\n",
              " 'considering',\n",
              " 'fucking',\n",
              " 'going',\n",
              " 'appealing',\n",
              " 'getting',\n",
              " 'coming',\n",
              " 'Everything',\n",
              " 'dealing',\n",
              " 'everything',\n",
              " 'something',\n",
              " 'during',\n",
              " 'dining',\n",
              " 'cooking',\n",
              " 'dining',\n",
              " 'editing',\n",
              " 'setting',\n",
              " 'amazing',\n",
              " 'rotating',\n",
              " 'Pricing',\n",
              " 'satisfying',\n",
              " 'disappointing',\n",
              " 'amazing',\n",
              " 'returning',\n",
              " 'running',\n",
              " 'being',\n",
              " 'thing',\n",
              " 'nothing',\n",
              " 'poisoning',\n",
              " 'thinking',\n",
              " 'something',\n",
              " 'going',\n",
              " 'disgusting',\n",
              " 'caring',\n",
              " 'bring',\n",
              " 'Disappointing',\n",
              " 'saying',\n",
              " 'going',\n",
              " 'coming',\n",
              " 'building',\n",
              " 'seating',\n",
              " 'dipping',\n",
              " 'setting',\n",
              " 'anything',\n",
              " 'drinking',\n",
              " 'serving',\n",
              " 'doing',\n",
              " 'putting',\n",
              " 'getting',\n",
              " 'looking',\n",
              " 'coming',\n",
              " 'staying',\n",
              " 'lacking',\n",
              " 'underwhelming',\n",
              " 'drawing',\n",
              " 'bring',\n",
              " ['Loved',\n",
              "  'Stopped',\n",
              "  'loved',\n",
              "  'ended',\n",
              "  'overpriced',\n",
              "  'tried',\n",
              "  'disgusted',\n",
              "  'shocked',\n",
              "  'recommended',\n",
              "  'performed',\n",
              "  'red',\n",
              "  'asked',\n",
              "  'overwhelmed',\n",
              "  'grossed',\n",
              "  'melted',\n",
              "  'provided',\n",
              "  'cooked',\n",
              "  'ordered',\n",
              "  'realized',\n",
              "  'Loved',\n",
              "  'lined',\n",
              "  'cooked',\n",
              "  'ripped',\n",
              "  'ripped',\n",
              "  'petrified',\n",
              "  'included',\n",
              "  'expected',\n",
              "  'seasoned',\n",
              "  'cheated',\n",
              "  'walked',\n",
              "  'smelled',\n",
              "  'tailored',\n",
              "  'arrived',\n",
              "  'roasted',\n",
              "  'added',\n",
              "  'cooked',\n",
              "  'passed',\n",
              "  'liked',\n",
              "  'managed',\n",
              "  'served',\n",
              "  'overpriced',\n",
              "  'checked',\n",
              "  'disappointed',\n",
              "  'red',\n",
              "  'decorated',\n",
              "  'served',\n",
              "  'watched',\n",
              "  'greeted',\n",
              "  'seated',\n",
              "  'waited',\n",
              "  'flavored',\n",
              "  'ordered',\n",
              "  'ordered',\n",
              "  'relocated',\n",
              "  'impressed',\n",
              "  'seated',\n",
              "  'priced',\n",
              "  'treated',\n",
              "  'ordered',\n",
              "  'used',\n",
              "  'handed',\n",
              "  'listed',\n",
              "  'missed',\n",
              "  'thrilled',\n",
              "  'inspired',\n",
              "  'desired',\n",
              "  'overcooked',\n",
              "  'decided',\n",
              "  'looked',\n",
              "  'dressed',\n",
              "  'treated',\n",
              "  'ordered',\n",
              "  'sucked',\n",
              "  'expected',\n",
              "  'sucked',\n",
              "  'imagined',\n",
              "  'served',\n",
              "  'arrived',\n",
              "  'satisfied',\n",
              "  'voted',\n",
              "  'insulted',\n",
              "  'disrespected',\n",
              "  'dreamed',\n",
              "  'lived',\n",
              "  'stepped',\n",
              "  'mixed',\n",
              "  'showed',\n",
              "  'realized',\n",
              "  'loved',\n",
              "  'needed',\n",
              "  'loved',\n",
              "  'wrapped',\n",
              "  'uninspired',\n",
              "  'Ordered',\n",
              "  'uploaded',\n",
              "  'covered',\n",
              "  'supposed',\n",
              "  'rolled',\n",
              "  'stayed',\n",
              "  'Based',\n",
              "  'received',\n",
              "  'privileged',\n",
              "  'charged',\n",
              "  'visited',\n",
              "  'proclaimed',\n",
              "  'disappointed',\n",
              "  'Stopped',\n",
              "  'dedicated',\n",
              "  'liked',\n",
              "  'disappointed',\n",
              "  'waited',\n",
              "  'waited',\n",
              "  'burned',\n",
              "  'waited',\n",
              "  'disappointed',\n",
              "  'Waited',\n",
              "  'disappointed',\n",
              "  'pulled',\n",
              "  'prepared',\n",
              "  'fried',\n",
              "  'passed',\n",
              "  'ordered',\n",
              "  'toasted',\n",
              "  'untoasted',\n",
              "  'figured',\n",
              "  'returned',\n",
              "  'eyed',\n",
              "  'disappointed',\n",
              "  'pleased',\n",
              "  'replenished',\n",
              "  'disappointed',\n",
              "  'treated',\n",
              "  'offered',\n",
              "  'tasted',\n",
              "  'dropped',\n",
              "  'decorated',\n",
              "  'served',\n",
              "  'walked',\n",
              "  'stuffed',\n",
              "  'located',\n",
              "  'Cooked',\n",
              "  'disappointed',\n",
              "  'screwed',\n",
              "  'frustrated',\n",
              "  'iced',\n",
              "  'stuffed',\n",
              "  'disappointed',\n",
              "  'grossed',\n",
              "  'enjoyed',\n",
              "  'looked',\n",
              "  'overwhelmed',\n",
              "  'stayed',\n",
              "  'smeared',\n",
              "  'stepped',\n",
              "  'tracked',\n",
              "  'tried',\n",
              "  'rushed',\n",
              "  'loved',\n",
              "  'Ordered',\n",
              "  'cooked',\n",
              "  'insulted',\n",
              "  'contained',\n",
              "  'enjoyed',\n",
              "  'relaxed',\n",
              "  'loved',\n",
              "  'acknowledged',\n",
              "  'trimmed',\n",
              "  'cooked',\n",
              "  'claimed',\n",
              "  'handled',\n",
              "  'asked',\n",
              "  'limited',\n",
              "  'boiled',\n",
              "  'liked',\n",
              "  'sliced',\n",
              "  'attached',\n",
              "  'humiliated',\n",
              "  'fried',\n",
              "  'impressed',\n",
              "  'disappointed',\n",
              "  'priced',\n",
              "  'disappointed',\n",
              "  'need',\n",
              "  'need',\n",
              "  'experienced',\n",
              "  'waited',\n",
              "  'seated',\n",
              "  'decided',\n",
              "  'pleased',\n",
              "  'recommended',\n",
              "  'helped',\n",
              "  'witnessed',\n",
              "  'Waited',\n",
              "  'waited',\n",
              "  'waited',\n",
              "  'checked',\n",
              "  'tasted',\n",
              "  'disappointed',\n",
              "  'served',\n",
              "  'rated',\n",
              "  'recommended',\n",
              "  'pulled',\n",
              "  'waited',\n",
              "  'acknowledged',\n",
              "  'perpared',\n",
              "  'dusted',\n",
              "  'powdered',\n",
              "  'enjoyed',\n",
              "  'expanded',\n",
              "  'ended',\n",
              "  'arrived',\n",
              "  'wanted',\n",
              "  'disappointed',\n",
              "  'need',\n",
              "  'checked',\n",
              "  'impressed',\n",
              "  'reheated',\n",
              "  'tasted',\n",
              "  'grilled',\n",
              "  'focused',\n",
              "  'roasted',\n",
              "  'asked',\n",
              "  'ignored',\n",
              "  'tasted',\n",
              "  'Ordered',\n",
              "  'greeted',\n",
              "  'seated',\n",
              "  'Tried',\n",
              "  'seated',\n",
              "  'Disappointed',\n",
              "  'ordered',\n",
              "  'constructed',\n",
              "  'fried',\n",
              "  'requested',\n",
              "  'used',\n",
              "  'tasted',\n",
              "  'drenched',\n",
              "  'tried',\n",
              "  'walked',\n",
              "  'expected',\n",
              "  'disappointed',\n",
              "  'mortified',\n",
              "  'impressed',\n",
              "  'refrained',\n",
              "  'pleased',\n",
              "  'loved',\n",
              "  'grilled',\n",
              "  'reminded',\n",
              "  'sucked',\n",
              "  'hooked',\n",
              "  'ordered',\n",
              "  'disappointed',\n",
              "  'seasoned',\n",
              "  'added',\n",
              "  'touched',\n",
              "  'fried',\n",
              "  'opened',\n",
              "  'impressed',\n",
              "  'watched',\n",
              "  'Tasted',\n",
              "  'ordered',\n",
              "  'received',\n",
              "  'impressed',\n",
              "  'overcooked',\n",
              "  'cooked',\n",
              "  'needed',\n",
              "  'served',\n",
              "  'ordered',\n",
              "  'overpriced',\n",
              "  'packed',\n",
              "  'opposed',\n",
              "  'priced',\n",
              "  'surprised',\n",
              "  'focused',\n",
              "  'overpriced',\n",
              "  'tried',\n",
              "  'enjoyed',\n",
              "  'qualified',\n",
              "  'tasted',\n",
              "  'hated',\n",
              "  'watched',\n",
              "  'fried',\n",
              "  'tried',\n",
              "  'helped',\n",
              "  'started',\n",
              "  'highlighted',\n",
              "  'used',\n",
              "  'enjoyed',\n",
              "  'ordered',\n",
              "  'tasted',\n",
              "  'asked',\n",
              "  'refused',\n",
              "  'tried',\n",
              "  'toasted',\n",
              "  'anticipated',\n",
              "  'unexperienced',\n",
              "  'insulted',\n",
              "  'disrespected',\n",
              "  'impressed',\n",
              "  'asked',\n",
              "  'rated',\n",
              "  'lacked',\n",
              "  'sliced',\n",
              "  'pulled',\n",
              "  'undercooked',\n",
              "  'seemed',\n",
              "  'watered',\n",
              "  'lacked',\n",
              "  'disappointed',\n",
              "  'overpriced',\n",
              "  'ensued',\n",
              "  'disappointed',\n",
              "  'placed',\n",
              "  'avoided',\n",
              "  'received',\n",
              "  'wanted',\n",
              "  'sucked',\n",
              "  'happened',\n",
              "  'owned',\n",
              "  'wanted',\n",
              "  'Overpriced',\n",
              "  'vomited',\n",
              "  'started',\n",
              "  'unwrapped',\n",
              "  'lacked',\n",
              "  'seemed',\n",
              "  'undercooked',\n",
              "  'closed',\n",
              "  'refried',\n",
              "  'dried',\n",
              "  'disappointed',\n",
              "  'impressed',\n",
              "  'wasted',\n",
              "  'poured']]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AhGq6De2Mvyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 3. Proceso de limpieza.**"
      ],
      "metadata": {
        "id": "70StdqAZa9E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 13.**  \n",
        "\n",
        "Ahora realiza un proceso de limpieza del corpus que incluya los siguientes procesos:\n",
        "\n",
        "*   Solo se deben considerar caracteres alfabéticos. Es decir, se eliminan todos los signos de puntuación y caracteres especiales.\n",
        "*   Todos los caracteres alfabéticos se transforman a minúsculas.\n",
        "*   Se deben eliminar todos los espacios en blanco adicionales que se puedan encontrar en cada comentario.\n",
        "\n",
        "Al finalizar dicho proceso de limpieza, imprime el resultado de los primeros 10 comentarios resultantes. \n",
        "   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xaDUFXHrMvX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea lista vacía para almacenar los comentarios\n",
        "corpus = []\n",
        "tokens_corpus = []\n",
        "\n",
        "#Ciclo for para todos los comentarios de la lista\n",
        "for i in range(0,len(docs)):\n",
        "\n",
        "  #Listas vacías para almacenar palabras y comentarios filtrados\n",
        "  comentario = docs[i]\n",
        "  palabras = []\n",
        "  palabras_comentario_corpus = []\n",
        "\n",
        "  #Separar por espacios y caracteres no alfanumericos para aislar sólo las palabras\n",
        "  palabras = re.split(r' |\\W', comentario)\n",
        "\n",
        "  #Ciclo para analizar todas las palabras\n",
        "  for j in range(0,len(palabras)):\n",
        "\n",
        "    #Si la entrada no está vacía, añadirla a la lista en minúsculas\n",
        "    if len(palabras[j]) > 0:\n",
        "\n",
        "      numeros = re.findall(r'\\d', palabras[j])\n",
        "\n",
        "      #No incluir números en la lista de tokens por comentario\n",
        "      if len(numeros) == 0:\n",
        "\n",
        "          palabras_comentario_corpus.append(palabras[j].lower())\n",
        "\n",
        "  #Incluir palabras encontradas en lista de tokens\n",
        "  tokens_corpus.append(palabras_comentario_corpus)\n",
        "  \n",
        "  #Unir todas las palabras al comentario\n",
        "  comentario_corpus = ' '.join(palabras_comentario_corpus)\n",
        "\n",
        "  #Añadir el comentario a la lista\n",
        "  corpus.append(comentario_corpus)\n",
        "\n",
        "#Se imprimen los primeros 10 comentarios\n",
        "corpus[0:10]"
      ],
      "metadata": {
        "id": "K3kQzPOPMx0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a34d26-47a4-4cb3-be62-ee5571ca4681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wow loved this place',\n",
              " 'crust is not good',\n",
              " 'not tasty and the texture was just nasty',\n",
              " 'stopped by during the late may bank holiday off rick steve recommendation and loved it',\n",
              " 'the selection on the menu was great and so were the prices',\n",
              " 'now i am getting angry and i want my damn pho',\n",
              " 'honeslty it didn t taste that fresh',\n",
              " 'the potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer',\n",
              " 'the fries were great too',\n",
              " 'a great touch']"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYEDlHSFMyJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 14.**  \n",
        "\n",
        "Con el resultado de la limpieza obtenido en la pregunta anterior, realiza ahora un proceso de tokenización por palabras del corpus. \n",
        "\n",
        "Es decir, al final de este proceso de tokenización, debes tener como resultado una lista de listas, donde cada comentario estará tokenizado por palabras.\n",
        "\n",
        "Al terminar calcula el total de tokens obtenido en todo el corpus. "
      ],
      "metadata": {
        "id": "WZwEhg2lUSAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se inicializa el contador en 0\n",
        "numero_de_tokens = 0\n",
        "\n",
        "#Se cuentan todos los elementos del corpus\n",
        "for i in range(0,len(tokens_corpus)):\n",
        "  numero_de_tokens = numero_de_tokens+len(tokens_corpus[i])\n",
        "\n",
        "#Se imprime el numero total de tokens\n",
        "print('El número total de tokens es: {}\\n'.format(numero_de_tokens))\n",
        "\n",
        "#Se imprimen las primeras 10 listas de tokens\n",
        "tokens_corpus[0:10]"
      ],
      "metadata": {
        "id": "kbAL9-v0V-jx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081941ae-74d3-48d7-ed08-3f1a991c925c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número total de tokens es: 11034\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['wow', 'loved', 'this', 'place'],\n",
              " ['crust', 'is', 'not', 'good'],\n",
              " ['not', 'tasty', 'and', 'the', 'texture', 'was', 'just', 'nasty'],\n",
              " ['stopped',\n",
              "  'by',\n",
              "  'during',\n",
              "  'the',\n",
              "  'late',\n",
              "  'may',\n",
              "  'bank',\n",
              "  'holiday',\n",
              "  'off',\n",
              "  'rick',\n",
              "  'steve',\n",
              "  'recommendation',\n",
              "  'and',\n",
              "  'loved',\n",
              "  'it'],\n",
              " ['the',\n",
              "  'selection',\n",
              "  'on',\n",
              "  'the',\n",
              "  'menu',\n",
              "  'was',\n",
              "  'great',\n",
              "  'and',\n",
              "  'so',\n",
              "  'were',\n",
              "  'the',\n",
              "  'prices'],\n",
              " ['now',\n",
              "  'i',\n",
              "  'am',\n",
              "  'getting',\n",
              "  'angry',\n",
              "  'and',\n",
              "  'i',\n",
              "  'want',\n",
              "  'my',\n",
              "  'damn',\n",
              "  'pho'],\n",
              " ['honeslty', 'it', 'didn', 't', 'taste', 'that', 'fresh'],\n",
              " ['the',\n",
              "  'potatoes',\n",
              "  'were',\n",
              "  'like',\n",
              "  'rubber',\n",
              "  'and',\n",
              "  'you',\n",
              "  'could',\n",
              "  'tell',\n",
              "  'they',\n",
              "  'had',\n",
              "  'been',\n",
              "  'made',\n",
              "  'up',\n",
              "  'ahead',\n",
              "  'of',\n",
              "  'time',\n",
              "  'being',\n",
              "  'kept',\n",
              "  'under',\n",
              "  'a',\n",
              "  'warmer'],\n",
              " ['the', 'fries', 'were', 'great', 'too'],\n",
              " ['a', 'great', 'touch']]"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZs_etmiV-fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 15.**  \n",
        "\n",
        "Finalmente, en este ejercicio definiremos nuestro conjunto de palabras \"stopwords\", las cuales deberás eliminar de todo el corpus. \n",
        "\n",
        "Recuerda que ejemplos de stopwords son artículos, adverbios, conectivos, etcétera, que tienen frecuencias de aparición muy altas en cualquier documento, pero que no brindan mucho significado en cuanto al significado de un enunciado.\n",
        "\n",
        "Con base a la lista de stopwords que se te proporciona, realiza un proceso de limpieza eliminando todas estas palabras del corpus obtenido en el ejercicio anterior.\n",
        "\n",
        "Obtener cuántos tokens/palabras quedan finalmente en todo el corpus.\n",
        "\n",
        "Obtener cuántos de estos tokens/palabras son diferentes, es decir, cuántos tokens únicos tendrá lo que llamaremos más adelante nuestro vocabulario."
      ],
      "metadata": {
        "id": "EFeu0OJ7WDPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Considera la siguiente lista como tu conjunto de stopwords:\n",
        "mis_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', 'now', 'll']"
      ],
      "metadata": {
        "id": "6FP4FF3KXGxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lista para almacenar el total de palabras del corpus\n",
        "palabras_vocabulario_corpus = []\n",
        "\n",
        "#Se crea una copia de todas las listas para evitar modificar el corpus original\n",
        "tokens_corpus_limpio = [x[:] for x in tokens_corpus]\n",
        "\n",
        "#Ciclo para analizar todos tokens del corpus\n",
        "for i in range(0, len(tokens_corpus_limpio)):\n",
        "\n",
        "  #Ciclo para encontrar todas las stop words\n",
        "  for j in range(0,len(mis_stopwords)):\n",
        "\n",
        "    #Contar el total de coincidencias para el stop word actual\n",
        "    numero_de_coincidencias = tokens_corpus_limpio[i].count(mis_stopwords[j])\n",
        "\n",
        "    #Si se tiene una o más coincidencias, se procede a eliminar todas las ocurrencias\n",
        "    if numero_de_coincidencias > 0:\n",
        "\n",
        "        for coincidencias in range(numero_de_coincidencias):\n",
        "          tokens_corpus_limpio[i].remove(mis_stopwords[j])\n",
        "\n",
        "  #Se añaden las palabras a la lista total de palabras disponibles\n",
        "  for k in range(0,len(tokens_corpus_limpio[i])):\n",
        "      \n",
        "    palabras_vocabulario_corpus.append(tokens_corpus_limpio[i][k])\n",
        "\n",
        "#Se inicializa contador en 0\n",
        "numero_de_tokens_limpio = 0\n",
        "\n",
        "#Se cuentan todos los elementos del corpus limpio\n",
        "for l in range(0,len(tokens_corpus_limpio)):\n",
        "  numero_de_tokens_limpio = numero_de_tokens_limpio+len(tokens_corpus_limpio[l])\n",
        "\n",
        "#Se imprime el numero total de tokens después de la limpieza\n",
        "print('El número total de tokens después de la limpieza es: {}\\n'.format(numero_de_tokens_limpio))\n",
        "\n",
        "#Se crea un a lista a partir de un set, para poder aislar las palabras sin importar el número de repeticiones\n",
        "vocabulario_corpus = list(set(palabras_vocabulario_corpus))\n",
        "\n",
        "#Se imprime el numero total de palabras únicas\n",
        "print('El número total de palabras únicas es: {}\\n'.format(len(vocabulario_corpus)))\n",
        "\n",
        "print(palabras_vocabulario_corpus[0:10])\n",
        "\n",
        "print(vocabulario_corpus[0:10])"
      ],
      "metadata": {
        "id": "CD8yjyq1ZrwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d898f0be-3f10-4ffa-bac1-fdf054c211d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número total de tokens después de la limpieza es: 5779\n",
            "\n",
            "El número total de palabras únicas es: 1907\n",
            "\n",
            "['wow', 'loved', 'place', 'crust', 'not', 'good', 'not', 'tasty', 'texture', 'nasty']\n",
            "['venture', 'much', 'mexican', 'dos', 'deeply', 'tables', 'crust', 'chicken', 'buying', 'fireball']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ZPi5prKZro5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Comentarios**\n",
        "\n",
        "Incluye finalmente tus comentarios de la actividad."
      ],
      "metadata": {
        "id": "NDbKkuxRbLoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Con esta actividad, se pudo ejercitar y comprender la importancia del uso de los módulos de expresiones regulares para el procesamiento de texto.*\n",
        "\n",
        "*En la primera sección, se pudieron cargar los datos y leerlos como texto plano incluyendo todos los caracteres que usualmente permanecen ocultos que se utilizan como separadores (espacios en blanco, saltos de línea, etc.), para después extraer sólo los comentarios por línea y asignarlos un elemento de una lista. En este caso, se límitó el número de módulos que podían ser usados en la actividad y los datos de texto se tienen que cargar de forma manual al ambiente temporal para poder procesarlos cada vez. Para cargarlos por medio de una URL, se requieren de módulos adicionales.*\n",
        "\n",
        "*En la segunda sección, se realizaron diversos ejercios donde se buscaron palabras con características específicas, como signos de admiración, caracteres repetidos, palabras compuestas, cantidades monetarias, palabras y/o comentarios con cierto número de letras minúsculas o mayúsculas, etc. Con estos ejercicios, se pudo comprobar la gran cantidad de opciones que se deben de considerar para aislar o separar palabras y/o comentarios, por ejemplo, para la separación de las palabras se utilizó principalmente el módulo de expresiones regulares, y se separaron las palabras por medio de los espacios en blanco y por medio de los caracteres especiales, dado que en muchos casos, las palabras resultantes de la búsqueda incluían caracteres adicionales no deseados. El método anterior, fue el más efectivo que se pudo encontrar tras diversas pruebas. Dependiendo del caso, se eliminaron algunos de los separadores para poder encontrar palabras compuestas (como las separadas por un guión o un apóstrofe) ya que separarlas cambia el significado de las mismas.*\n",
        "\n",
        "*Por último, se realizó un proceso de determinación y limpieza del corpus lingüístico, removiendo todos los caracteres especiales y numéricos para que quedaran únicamente los caracteres alfabéticos en minúsculas. Se utilizó un método muy similar al anterior, pero en este caso, se separaron las palabras de cada comentario en tokens, empleando todos los espacios en blanco y todos los caracteres no alfanuméricos. Posteriormente se eliminaron todas las stop words de los tokens, determinando el total del tokens disponibles para después crear una lista por medio de un set para determinar el vocabulario con todas las palabras únicas que existen en el texto.*\n",
        "\n",
        "*Para el ejercicio de limpieza, se observó que el método de separación requiere lógicas adicionales para manejar las palabras compuestas por apóstrofes (como didn´t) ya que al elminar y separar los caracteres especiales, permanece la 'n', la palabra no coincide exactamente con la stop word y por lo tanto no se elimina de los tokens. Una solución simple, sería agregar estas variantes de las palabras con 'n' o el caracter correspondiente al final a los stop words para que se elimine satisfactoriamente.*\n",
        "\n",
        "*Como conclusión breve, los resultados pueden ser muy variables dependiendo del enfoque y la lógica que se emplee para el procesamiento de texto, por lo que el total de resultados obtenidos puede estar dentro de un rango aceptable para cada uno de los ejercicios.*"
      ],
      "metadata": {
        "id": "o7fzbvqVbUGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Fin de la Actividad de la semana 2.**"
      ],
      "metadata": {
        "id": "PHaKw_6Ldbaf"
      }
    }
  ]
}